{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from v1sh_model.inputs.visualize import visualize_input\n",
    "from v1sh_model.models.V1_model_1 import V1_model_1 as V1_model\n",
    "from v1sh_model.inputs.examples import neighboring_textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and test the FullModel\n",
    "seed = 42\n",
    "model = V1_model(seed=seed, alpha_x=1.0, alpha_y=1.0)\n",
    "A, C = neighboring_textures(22, 60, 2.0)\n",
    "\n",
    "T = 12.0\n",
    "dt = 0.001\n",
    "X_gen, Y_gen, I = model.simulate(\n",
    "    A, C, dt=dt, T=T, verbose=False, noisy=True, mode=\"wrap\"\n",
    ")\n",
    "\n",
    "# Time points in seconds to plot\n",
    "time_points = np.array([0.7, 0.9, 1.2, 1.4, 1.8])\n",
    "steps = [int(t / dt) for t in time_points]\n",
    "\n",
    "# average of input across columns for the orientation of the target bar\n",
    "X_per_column = np.concatenate(\n",
    "    [model.g_x(X_gen[:, :, :30, 6]).mean(axis=1), model.g_x(X_gen[:, :, 30:, 0]).mean(axis=1)], axis=1\n",
    ")\n",
    "# Plot input\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6, 5), constrained_layout=True, dpi=400)\n",
    "visualize_input(A, C, verbose=False, axis=axes[0])\n",
    "axes[0].set_title(r\"Input Image $\\hat{I}_{i \\theta}$ to model\")\n",
    "\n",
    "# visualize_output(A, I.max(axis=-1), verbose=True)\n",
    "# n_cols = A.shape[1]\n",
    "# plt.xticks(\n",
    "#     np.arange(0, n_cols, 1),\n",
    "#     labels=[f\"{i}\" for i in range(1, n_cols + 1)]\n",
    "# )\n",
    "# # plt.tick_params(axis='x', length=0)  # hide tick marks\n",
    "# plt.show()\n",
    "\n",
    "# Plot model dynamics, see fig. 5.21 in \"Understanding Vision\" (Li Zhaoping, 2014)\n",
    "x_axis = np.arange(X_per_column.shape[1])  # column indices\n",
    "for t_idx, step in zip(time_points, steps):\n",
    "    # Neural response: sum over orientation channels (axis=-1)\n",
    "    response = X_per_column[step]\n",
    "    axes[1].plot(x_axis, response, label=f\"t = {t_idx:.1f}\")\n",
    "\n",
    "avg_response = X_per_column.mean(axis=0)\n",
    "axes[1].plot(\n",
    "    x_axis, avg_response, label=\"Temporal average\", linewidth=3, linestyle=\"--\", color=\"k\"\n",
    ")\n",
    "\n",
    "axes[1].set_xlabel(\"Texture column number\")\n",
    "axes[1].set_ylabel(\"Model response \" + r\"$g_x(x)$\")\n",
    "axes[1].set_ylim(-0.1, 1.1)\n",
    "axes[1].set_xlim(0, 59)\n",
    "axes[1].legend(framealpha=0.8, loc=\"upper left\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- too fast?\n",
    "- not as smooth?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
